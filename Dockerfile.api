ARG LOAD_CUDA=base

FROM python:3.10-slim AS python_base
FROM pytorch/pytorch:2.6.0-cuda12.6-cudnn9-devel AS python_cuda

FROM python_${LOAD_CUDA} AS models



# FROM pytorch/pytorch:2.6.0-cuda12.6-cudnn9-devel AS models
# FROM python:3.10-slim AS models
# FROM public.ecr.aws/neuron/pytorch-inference-neuronx:2.5.1-neuronx-py310-sdk2.21.1-ubuntu22.04

# ENV DEBIAN_FRONTEND=noninteractive

WORKDIR /app

COPY ./backend/models ./models/

FROM models

# Install system dependencies
RUN apt-get update && \
    apt-get install -y python3 python3-pip openssh-client

RUN pip3 install --upgrade pip

WORKDIR /app

COPY ./backend/ml ./ml/
COPY ./backend/parsing ./parsing/
COPY ./backend/dataset_utils ./dataset_utils/
COPY ./backend/api_utils ./api_utils/
COPY ./backend/.config.txt ./backend/api.py ./backend/requirements.txt ./backend/config.py ./backend/.env ./backend/jwt_keygen.sh ./
COPY --from=models /app/models ./models/
RUN pip3 install -r ./requirements.txt
# RUN pip3 install torch-neuron --index-url https://pip.repos.neuron.amazonaws.com
# RUN pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126

ENV FLASK_ENV=production

EXPOSE 80
RUN bash ./jwt_keygen.sh
CMD ["gunicorn", "-b", ":80", "api:app", "--timeout", "240"]



### To run interactive:
# docker run -it --runtime=nvidia react-flask-app-api:latest /bin/bash

### To run:
# docker run --runtime=nvidia -p 80:8080 react-flask-app-api
# docker run --device=/dev/neuron0 -p 80:8080 react-flask-app-api

### build:
# docker build -f Dockerfile.api -t react-flask-app-api . --build-arg LOAD_CUDA=base